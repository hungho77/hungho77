# Hi, I'm Ho Thinh Hung ğŸ‘‹

Senior AI Engineer focused on **LLM systems**, **real-time computer vision**, and **GPU-accelerated inference at scale**.  
I design and ship **production-grade AI systems** â€” from multi-GPU LLM serving to high-throughput, low-latency video analytics.

ğŸ“ Ho Chi Minh City, Vietnam  
ğŸ“§ hothinhhung77@gmail.com  
ğŸ”— LinkedIn: https://www.linkedin.com/in/hunho77  
ğŸ™ GitHub: https://github.com/hungho77

---

## ğŸ§  Professional Focus

- **LLM Engineering & Serving** â€” vLLM, Triton, TensorRT, CUDA, multi-GPU (H100)
- **Real-time Computer Vision** â€” DeepStream, YOLO, tracking, face recognition
- **High-performance AI Systems** â€” low latency, high throughput, 99% uptime
- **Multimodal AI** â€” Vision Ã— Language Ã— Speech
- **Production ML** over research-only prototypes

---

## ğŸš€ Selected Projects

### ğŸ¤– Multi-Agent Digital Human Virtual Reception
A WebRTC-based **AI virtual receptionist** delivering sub-second end-to-end latency.

- Designed a **multi-agent architecture** (Perception, Dialogue, Task, Avatar)
- Real-time ASR, emotion detection, speaker diarization over streaming audio
- LLM-driven dialogue with MCP-style planning, tool use, and session memory
- RAG with hybrid retrieval (BM25 + dense) using FAISS / pgvector
- Achieved **~700ms P95 latency** from listen â†’ think â†’ speak in kiosk tests  

**Tech:** LLMs, WebRTC, Kafka, Redis, CUDA, Docker

---

## ğŸ›  Tech Stack

**Languages**
- Python, C++

**LLM & Inference**
- vLLM, LMCache, Triton Inference Server
- TensorRT, ONNX Runtime
- OpenAI-compatible APIs (blocking & streaming / SSE, WebSocket)

**Computer Vision**
- YOLO, DeepStream, OpenCV
- Face recognition, multi-object tracking, OCR
- Vision-Language Models (BLIP-2)

**Systems & Infrastructure**
- CUDA, mixed-precision & memory optimization
- Kafka, Redis, MongoDB
- Docker, REST, WebSocket

---

â­ I enjoy building **fast, reliable, and scalable AI systems** that work in real-world production environments.
